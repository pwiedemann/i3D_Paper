%-------------------------------------------------------------------------
\section{Related Work}
%-------------------------------------------------------------------------
\subsection*{Precomputed Radiance Transfer and Extensions} 
PRT was first proposed by \cite{sloan2002precomputed} to address global illumination effects on objects for real-time applications. This technique exploits the limitation of static objects by making a single pre-computation step of the \textit{Transfer Function}, allowing fast computations at runtime. \\
\\
PRT for dynamic or deformable objects would require pre-computing sequences of \textit{Transfer Functions} to account for every pose, resulting in data sets that expand in proportion to the number of poses; hence, rapidly becoming unwieldy for such applications.\\
Our aim is to extend traditional PRT to arbitrary deformable geometries while preserving a rather manageable and limited storage consumption. \\
One extension of PRT was introduced by  \cite{local-deformable-precomputed-radiance-transfer} to enable transfer of local illumination effects, such as bumps and wrinkles, to arbitrary deformations.  Nevertheless, this method cannot account for distant self-shadowing effects, such as cast shadows from a limb to the trunk from an articulated figure. Our intention is to enhance PRT to account for such global self-shadowing effects.\\
%Other approaches \cite{Implicit_Visibility, Implicit_Visibility_2} circumvent the pre-computation problem by proposing an alternative algorithm to efficiently compute an approximation of the Visibility Function (implicit in $T$) at near real-time frame rates. ( However, ... )\\
%Data-based approaches, in principle aim to reduce the dimensionality of the problem, and thus the storage consumption, by exploiting the information of the dataset:\\
%A data-based compression scheme of precomputed radiance transfer matrices is presented in \cite{SkinningPRT}. Precomputed transfer matrices of surface samples, deformed by \textit{skinning}, are clustered and compressed, such that de-compression and interpolation can be performed efficiently.\\  
%An appearance model, that approximates PRT lighting, is presented in  \cite{James_Fatahalian}. The model is based on a reduced state space of deformable shapes that allows only very limited kind of poses/shapes. 
Other approaches, rely on exploiting the information of a specific dataset to reduce the dimensionality of the problem and thus the storage consumption. For instance, \cite{SkinningPRT} introduce a data-based compression scheme of precomputed radiance transfer matrices .Precomputed transfer matrices of surface samples, deformed by \textit{skinning}, are clustered and compressed, such that de-compression and interpolation can be performed efficiently.
\\  
An appearance model, that approximates PRT lighting, is presented in  \cite{James_Fatahalian}. The model is based on a reduced state space of deformable shapes that allows only very limited kind of poses/shapes. 
\\
Similarly, \cite{MoMoPRT} suggest a linear self-shadowing model to predict the coefficients of the \textit{Transfer Function} from shape parameters of Morphable Models (MoMo) \cite{MoMo}. Their proposed model show good results while operating within the reduced shape space of MoMo; nevertheless, our aim is to provide a more powerful PRT-model, that endows good approximations for more arbitrary deformations living within a larger and more generic shape space. To that end, we rather propose a non-linear model with well known strong generalisation properties, namely a deep Convolutional Neural Network \cite{DL_nature, ImageNet_CNN, CNN_videoClassification}.  
\subsection*{Deep Learning Appearance on Geometry Data} 
Deep Learning (DL) has been used for appearance predictions before, albeit mostly focusing on learning illumination effects from screen-space data. In  \cite{Nalbach2017b} and \cite{DBLP} learning is conducted on image data gathered from the shading buffers to predict illumination effects in screen space. However, image-based approaches often suffer from significant information loss, depending on the visibility of the object, and do not leverage the underlying structure of the geometry. These factors make the learning procedure harder requiring large amounts of training data.
\\
Alternatively, we propose directly learning \textbf{on} geometric data.  However, learning on surfaces using CNN's is a rather challenging task. Due to the non-Euclidean nature of the domain basic operations such as the convolution are not well-defined, leading current research down different paths on the effort to adapt CNN's to such domains (we refer the readers to \cite{Geometric_deep_learning} and \cite{DeepGeoCourse} for a more detailed overview).
\\
One approach, is to circumvent this difficulty by representing the surface data as a probability distribution on a  3D grid and apply volumetric CNN's \cite{3d_ShapeNets}. However, this extrinsic representation has many shortcomings when applied to deformable geometries: They are very sensitive to deformations are computationally expensive and, equally to the screen-space strategies, require abounding training data.
\\
Conversely, strategies for intrinsic shape representations propose different adaptations of CNN's to such domains \cite{ShapeNet1, BoscainiMRB16, CNN_on_Torus}.
\\
\\ 
In our work, we chose a shape representation that, on the one hand, can endow the underlying shape structure, and on the other hand, supports standard 2D convolution operations. We adopt a parametric approach introduced by \cite{gu2002geometry}, called \textit{Geometry Image}, that transforms a discrete surface into a regularly sampled unit square. This approach has been extended by \cite{Spherical_Parametrization} to smooth out some critical limitations of the original work and later validated by \cite{sinha2016deep} as suitable framework for deep learning purposes.
\\
To the extend of our knowledge, our work is the first to tackle the problem of PRT for deformable objects from a Deep Learning perspective and especially on manifold like data. 


