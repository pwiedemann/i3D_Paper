\section{Introduction}

Rendering photo-realistic appearances entails solving the \textit{rendering equation} for each point on an objects surface. This computation can be extremely demanding, especially considering global illumination effects where the problem becomes highly recursive. \\
\textit{Precomputed Radiance Transfer} (PRT) is a technique addressed to overcome this computational overkill, simplifying the rendering equation but still enabling high-quality renderings for complex illuminations. The quintessence is to perform a single pre-computation step of the light-transport information and only evaluate the equation at runtime.\\
Classic PRT algorithms function well for static scenes; however, these are destined to fail eyeing dynamic and/or interactive environments, in which considered objects undergo significant deformations.
Responsible is a term in the rendering equation called the \textit{transfer function} which is fully dependent on the shape of the surface. That is, any object deformation implies a re-computation of the \textit{transfer function},  requiring expensive ray-casting. Hence, using classic PRT to render deformable objects would involve pre-computing large amounts of data, leading to immense storage consumptions. Hence, rapidly becoming unwieldy and innefficient since memory IO's operations can be 3 orders of magnitudes energy demanding than floating point summations or multiplications \cite{ComputingEnergy}. \\
On top of that, the costly and memory consuming pre-computation of these \textit{transfer functions}, presumes knowledge of all future deformations of the regarded object. Nevertheless, dynamic or interactive scenes may require on-the-fly adaptive, previously unknown, object deformations. Examples of such are: 
interactive physically based deformations for cloth or soft-bodies [find references] ; 
or more recent developements in the field of automatic character animations involving on-the-fly pose adaptation \cite{DeepHuman,Holden2017, QuadrupedMotion}. \\
\\
We propose a Deep Learning framework addressed to overcome the limitations of traditional PRT algorithms described above. In particular, we replace expensive ray-casting algorithms by a deep Convolutional Neural Network (CNN) that, for a given deformation, infers the corresponding set of SH - coefficients that represent the \textit{transfer function}. 
Thus, enabling a compact PRT representation that maintains a constant/fix storage consumption, regardless of the number of deformations. Moreover, due to the inherent generalisation capabilities of DNN's, our method is able to accurately predict appearances of previously unknown shapes. We call this compact self-shadowing technique \textit{Deep Precomputed Radiance Transfer} (DPRT). \\
\\
Finding an appropriate representation of shape, or manifold like, data to use in a CNN framework is a challenging task due to the non-Euclidean nature of the domain in which the data is defined on. Here, basic operations, such as the convolution, are not well defined being a major impediment for Deep Learning (DL) to fully flourish in this particular field. Nonetheless, more recently some authors have started to address the paradigm of DL on non-Euclidean data proposing a variety of approaches \cite{Masci2015ShapeNetCN, Geometric_deep_learning, CNN_on_Torus} (for further reading: \cite{GeoDeepLearning}). \\
In particular, we propose learning on \textit{geometry images}, a parametrisation proposed by \citep{gu2002geometry} and further explored within the DL context by \cite{Sinha2016DeepL3}.   
\\
\\
The main contributions of our approach, is an extension of PRT that: 
\begin{itemize}
\item enables accurate appearance predictions of more general and adaptive deformations than previous approaches,
\item while maintaining a much smaller and compact representation. 
\end{itemize}
