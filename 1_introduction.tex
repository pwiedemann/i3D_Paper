\section{Introduction}

Rendering photo-realistic appearances entails solving the \textit{rendering equation} for each point on an objects surface. This computation can be extremely demanding, especially considering global illumination effects where the problem becomes highly recursive. \\
\textit{Precomputed Radiance Transfer} (PRT) is a technique addressed to overcome this computational overkill, simplifying the rendering equation but still enabling high-quality renderings for complex illuminations. The quintessence is to perform a single pre-computation step of the light-transport information and only evaluate the equation at runtime.\\
Classic PRT algorithms function well for static scenes; however, these are destined to fail eyeing dynamic and/or interactive environments, in which considered objects undergo significant deformations.
Responsible is a term in the rendering equation called the \textit{transfer function} which is fully dependent on the shape of the surface. That is, any object deformation implies a re-computation of the \textit{transfer function},  requiring expensive ray-casting. Hence, using classic PRT to render deformable objects would involve pre-computing large amounts of data, leading to immense storage consumptions. \\
On top of that, the costly and memory consuming pre-computation of these \textit{transfer functions}, presumes knowledge of all future deformations of the regarded object. Nevertheless, dynamic or interactive scenes may require on-the-fly adaptive, previously unknown, object deformations. Examples of such are: 
interactive physically based deformations for cloth or soft-bodies [find references] ; 
or more recent developements in the field of automatic character animations involving on-the-fly pose adaptation [for instance, Holden paper, deepmotion,etc...]. \\
\\
We propose a Deep Learning framework addressed to overcome the limitations of traditional PRT algorithms described above. In particular, we replace expensive ray-casting algorithms by a deep Convolutional Neural Network (CNN) that, for a given deformation, infers the corresponding set of SH - coefficients that represent the \textit{transfer function}. 
Thus, regardless of the number of deformations our method maintains a constant size (fixed storage consumption). Moreover, due to the inherent generalisation capabilities of DNN's, DPRT is able to accurately predict appearances of previously unknown shapes. We call this approach \textit{Deep Precomputed Radiance Transfer} (DPRT). \\
\\
Finding an appropriate representation of shape, or manifold like, data to use in a CNN framework is a challenging task due to the non-Euclidean nature of the domain in which the data is defined on. Here, basic operations, such as the convolution, are not well defined being a major impediment for Deep Learning (DL) to fully flourish in this particular field. Nonetheless, more recently some authors have started to address the paradigm of DL on non-Euclidean data proposing a variety of approaches \cite{Masci2015ShapeNetCN, Geometric_deep_learning, CNN_on_Torus} [\url{http://geometricdeeplearning.com/}]. \\
In particular, we propose learning on \textit{geometry images}, a parametrisation proposed by \citep{gu2002geometry} and further explored within the DL context by \cite{Sinha2016DeepL3}.   
\\
\\
The main contributions of our approach are: 
\begin{itemize}
\item enabling arbitrary and adaptive deformations,
\item while maintaining a compact representation. 
\end{itemize}
